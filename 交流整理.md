**下一周的todo-lists**

- [x] r3live或者immesh、voxelmap、voxelmap++的可展示文件 | 在voxelmap以及plus版本里面，plane的色彩信息表示什么? 
- [ ] voxelmap与voxelmap++这两个算法在 <font color=blue>里程计精度</font>以及运行时间上面的比较 | 以及这两个算法是不是都提到了关于精度的改进工作
- [x] 视觉建图与lidar建图的融合

  - r3live中视觉渲染部分能不能单独取出来(形成一个独立的模块) | 还要读完整个r3live中利用视觉进行渲染的 pipeline

  - **本周最重要的工作是完成实时mesh图的重建工作**
- [ ] 调研一下mesh的重建工作 | 需要其与RGB-D融合





现在的两个方案 (1) 生成mesh之后在贴图做优化 (2) 还是在生成mesh的时候就直接使用color信息融合

- lvisam(直接使用m2DGR-plus数据集运行) —— 现在可以将lvisam与Immesh结合作为下一步工作的baseline (但是需要确定其效果不好的部分是什么原因导致的-是一些参数没有调整好，还是算法本身的问题 - 这部分最重要!! ) | 使用的数据集最好是m2DRG-plus 



1. https://github.com/HViktorTsoi/rs_to_velodyne 关于m2DGR-plus数据集中的lidar处理
2. https://github.com/Livox-SDK/LIO-Livox livox中有一个动态点云剔除的操作(做的还是比较好) | 无论是定位还是建图都是需要使用的部分
3. 骏杰之前提到了一种泊松分布的方法其对应的Mesh的重建结果会好一些 (现在这个方法暂时有一点问题)
4. 小六的学习小组里面会有在m2DGR数据集中使用的lvisam算法 (比之前使用的lvisam_easy_used的效果要好一些) | 这样的好处是能再运行更多的序列测试算法的效果



ImMesh中使用本身的方法与当前存在的mesh重建方法： 

- TSDF-based(PCL中使用的)
- OpenMVS
- Poisson surface reconstruction

ImMesh中的对比实验：mesh重建对比都使用Ground-truth的位姿进行offline reconstruction。









r3live中需要全局点云数据的线程

- mesh 线程
- rendering 线程
- Pub线程

如果里程计部分直接将点云数据送入到全局点云数据中，而不是现在的将数据进行打包发送，那么将会出现第四个线程需要全局线程。这样感觉会导致部分线程耽误了其他线程的运行。



















7.14 

下一周需要的work

- 群里面对应的论文
- 尝试给车上面装各种传感器
- 测试各个模块运行时间 - 判断一下这些模块运行的时间情况









注意在C++调试过程中，如果cmakelists.txt 中使用 release 以及在set选项的时候使用 O0 优化设置 —— 在这种情况下 会让整个程序在debug的时候程序实际停留的位置与断点的位置不一致。



https://xueshi.io/2022/12/03/shared-ptr-data-race-with-multithread/







7.22 修改mesh可视化结果

- 对目前的运行时间进行log读取 - 增加log文件的输出来应对更多情况
- m2DGR hall-05 数据 | 在室内环境中调试 color-mesh | openGL color-mesh保存
    - 是不是扫描到的点云过于复杂了 —— 导致最后的的mesh很杂乱, 效果都不是很好
    - 调试immesh中的参数, 使mesh生成的效果更好一些
-  学习初始化部分的代码 —— 这样后续也可以使用在 multi-SLAM 中使用
- 阅读论文 (群里面的论文应该多读一下)
- C++ 调试部分 | 按理这部分应该不是很重要 ( 但是我已经调试了一周, 总要进行整理 )
- 关于switch-slam中的切换方案进行整理 —— 毕竟还是需要进行corner detection



PS:

- 内存分析工具有点小问题 | GUI关闭之后程序也死了是什么鬼, 导致我离线分析一直有问题
- 互斥锁本身就是线程安全的，多线程访问互斥锁也没有关系

- m2DGR hall 05 数据集中只会使用lidar传感器，没有使用imu —— 所以导致出现里程计漂移的问题 | 之前能运行的m2DGR walk出现问题应该是里程计部分计算的频率下降导致的漂移问题 (从处理速度上获取信息)

- https://blog.csdn.net/p942005405/article/details/103766900 感觉这部分对应的就是mesh重建中使用image渲染的tutorial









**一些剩余问题....**

PS: 对比一下voxelmap以及immesh中的plane生成，为什么这里有这么大的区别(原版的voxelmap非常不好用) | 而且进行图像信息生成的时候, 应该先从一帧中读取



点云的配准形式使用的数据结构

- voxelmap: 用的是voxel中估计plane那一套来进行位姿计算

- ikd-tree: Fastlio实现路线



PS：ig-lio: An incremental gicp-based tightly-coupled lidar-inertial odometry

关于退化场景又专门的detectin modular

至少介绍了三篇方法来帮助使用退化场景的detection，本文自己也使用了一种方法来实现退化场景的检测

对于lidar的退化场景是不是存在groundtruth来判断corner detection检测的是否正确

























- 因为VIO在帮助定位上面是有一些鸡肋的，所以这里会给VIO加入odom传感器进行一些处理。但是在实际进行测试的时候，可以使用多种开源数据集进行测试，比如m2DGR/m2DGR-plus数据集进行without/without odom的数据集。

- 主动测试退化场景的方法 | mm-lins上面对于退化场景的表示还是比较局限的，因为其只是使用了一个lidar被包裹的情况来说明退化场景出现了。而正常的退化场景应该是在长直道这些场景下出现lidar里程计的退化。
- 目前想使用的groundfusion+voxelmap或者lio做为子系统来相互调用，来解决corner case下的作用 —— corner case的部分可以作为第四个创新点来实现



没想到8月份就要开始写论文，实在是太早了，2~3天更新一版的话，这种文字什么的肯定会表示的更好



